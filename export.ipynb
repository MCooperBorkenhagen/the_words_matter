{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "# Set the print options\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.genfromtxt('data/samples.csv', delimiter=\",\").astype(bool)\n",
    "holdouts = np.genfromtxt('data/holdouts.csv', delimiter=\",\").astype(bool)\n",
    "tests = np.genfromtxt('data/tests.csv', delimiter=\",\").astype(bool)\n",
    "words = pd.read_csv('data/kidwords/kidwords.csv', names = [\"word\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulate dichotomous accuracy per model and place in a file\n",
    "Extract the accuracy data for each sample and write to file. This takes a minute because it requires iterating through all the written accuracy files. Note that the accuracy summary datafile writes the accuracies out in a random order over rows, so you might need to arrange the rows if you want them to be in an orderly fashion.\n",
    "\n",
    "This routine was copied from elsewhere and needs to be inspected. The code doesn't look right to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory - used for several chunks below\n",
    "directory = 'outputs/brute_force_2_with_frequency/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Specify the indices\n",
    "\n",
    "# Iterate over every file in the specified directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"accuracies.csv\"):\n",
    "        # Extract the ID and level from the filename\n",
    "        id_start = filename.find(\"sample_\") + len(\"sample_\")\n",
    "        id_end = filename.find(\"hidden\")\n",
    "        ID = int(filename[id_start:id_end].replace(\"_\", \"\"))\n",
    "\n",
    "        level_start = filename.find(\"hidden_\") + len(\"hidden_\")\n",
    "        level_end = filename.find(\"accuracies\")\n",
    "        level = int(filename[level_start:level_end].replace(\"_\", \"\"))\n",
    "\n",
    "        # Read the csv file\n",
    "        data = np.genfromtxt(os.path.join(directory, filename), delimiter=',')\n",
    "\n",
    "        # Tabulate the number of values equal to one and less than one\n",
    "        equal_to_one = np.sum(data == 1)\n",
    "        less_than_one = np.sum(data < 1)\n",
    "\n",
    "        # Tabulate the values for each set of indices\n",
    "        # if you want to determine\n",
    "        train = np.sum(data[samples[:,ID]] == 1)/sum(samples[:,ID])\n",
    "        test = np.sum(data[tests[:,ID]] == 1)/sum(tests[:,ID])\n",
    "        holdout = np.sum(data[holdouts[:,ID]] == 1)/sum(holdouts[:,ID])\n",
    "\n",
    "        # Save the results\n",
    "        results.append([ID, level, train, test, holdout])\n",
    "\n",
    "# Convert the results to a numpy array and write to a csv file\n",
    "results_array = np.array(results)\n",
    "\n",
    "\n",
    "pd.DataFrame(results_array).to_csv('outputs/brute_force_2_with_frequency/tabulated_dichotomous_accuracy.csv', index = False, header = [\"model_id\", \"hidden\", \"train\", \"test\", \"holdout\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMEM subset data\n",
    "Generate a random sample of 200 model IDs to make the subset data for the LMEM (which DK is running)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the MSE (files labeled with \"error\") data for the LMEM subset (the LMEMs can't be run on the entire dataset). This routine does look correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chunk helps subset to create data for an LMEM, if you need to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(345)\n",
    "\n",
    "N = 1000\n",
    "\n",
    "numbers = [str(i) for i in range(10000)]\n",
    "subset = random.sample(numbers, N)\n",
    "\n",
    "filenames = []\n",
    "for filename in os.listdir(directory):\n",
    "    for ID in subset:\n",
    "        if filename.startswith(\"sample_\"+ID+\"_\"):\n",
    "            if \"error\" in filename:\n",
    "              if filename or \"hidden_20\" in filename or \"hidden_30\" in filename or \"hidden_40\" in filename:\n",
    "                  filenames.append(filename)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate a file with all the right data, but is much larger (doesn't subset by sampling). It allow you to identify data for certain values of hidden unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"sample_\"):\n",
    "        if \"error\" in filename:\n",
    "            if \"hidden_10_\" in filename or \"hidden_20\" in filename or \"hidden_30\" in filename or \"hidden_40\" in filename:\n",
    "                filenames.append(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for filename in filenames:\n",
    "\n",
    "    id_start = filename.find(\"sample_\") + len(\"sample_\")\n",
    "    id_end = filename.find(\"hidden\")\n",
    "    ID = int(filename[id_start:id_end].replace(\"_\", \"\"))\n",
    "\n",
    "    level_start = filename.find(\"hidden_\") + len(\"hidden_\")\n",
    "    level_end = filename.find(\"error\")\n",
    "    level = int(filename[level_start:level_end].replace(\"_\", \"\"))\n",
    "\n",
    "    one_file = pd.read_csv(f'outputs/brute_force_2_with_frequency/{filename}', names = [\"mse\"])\n",
    "    one_file['word'] = words['word']\n",
    "    one_file['model_id'] = ID\n",
    "    one_file['hidden'] = level\n",
    "    one_file['train'] = samples[:,ID]\n",
    "    one_file['test'] = tests[:,ID]\n",
    "    one_file['holdout'] = holdouts[:,ID]\n",
    "    dfs.append(one_file)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# this function needs to change if you are calculating accuracy from featurewise accuracy rather than from mse:\n",
    "df['accuracy'] = df['mse'].apply(lambda x: 0 if x > 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file for LMEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mse', 'word', 'model_id', 'hidden', 'train', 'test', 'holdout',\n",
       "       'accuracy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If identifying a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['test'] == False]\n",
    "df = df[['model_id', 'hidden', 'word', 'mse', 'train', 'holdout']]\n",
    "\n",
    "# if you have generated a subset:\n",
    "df.to_csv('outputs/brute_force_2_with_frequency/subset_data_for_lmem_v2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# here is the entire dataset if you want to write it (it is very large)\n",
    "# #df.to_csv('outputs/brute_force_2_with_frequency/data_for_lmem.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout = df[df['holdout']==True]\n",
    "\n",
    "data_by_model_for_lmem = df_holdout.groupby(['model_id', 'hidden']).agg(\n",
    "    mse_mean=('mse', 'mean'),\n",
    "    mse_sd=('mse', 'std'),\n",
    "    count=('mse', 'size')\n",
    ").reset_index()\n",
    "\n",
    "df_train = df[df['train']==True]\n",
    "\n",
    "data_by_word_for_lmem = df_train.groupby(['word', 'hidden']).agg(\n",
    "    mse_mean=('mse', 'mean'),\n",
    "    mse_sd=('mse', 'std'),\n",
    "    count=('mse', 'size')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_model_for_lmem.to_csv('~/Desktop/data_by_model_for_lmem.csv', index=False)\n",
    "data_by_word_for_lmem.to_csv('~/Desktop/data_by_word_for_lmem.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulate summary data per model\n",
    "Using the \"...summary.csv\" files, tabulate the summary data for every model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "cols_in = ['hidden_units', 'accuracy_train', 'mse_train', 'accuracy_test', 'mse_test', 'accuracy_holdout', 'mse_holdout']\n",
    "cols_out = ['model_id', 'hidden_units', 'accuracy_train', 'mse_train', 'accuracy_test', 'mse_test', 'accuracy_holdout', 'mse_holdout']\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"summary.csv\"):\n",
    "        # Extract the ID and level from the filename\n",
    "        id_start = filename.find(\"sample_\") + len(\"sample_\")\n",
    "        id_end = filename.find(\"hidden\")\n",
    "        ID = int(filename[id_start:id_end].replace(\"_\", \"\"))\n",
    "\n",
    "        # Read the csv file\n",
    "        summary = pd.read_csv(os.path.join(directory, filename))[cols_in]\n",
    "        summary['model_id'] = ID\n",
    "\n",
    "        # Save the contents\n",
    "        results.append(summary)\n",
    "        \n",
    "\n",
    "pd.concat(results).reindex(columns=cols_out).to_csv('outputs/brute_force_2_with_frequency/model_summaries.csv', index = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
