{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "# Set the print options\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.genfromtxt('data/samples.csv', delimiter=\",\").astype(bool)\n",
    "holdouts = np.genfromtxt('data/holdouts.csv', delimiter=\",\").astype(bool)\n",
    "tests = np.genfromtxt('data/tests.csv', delimiter=\",\").astype(bool)\n",
    "words = pd.read_csv('data/kidwords/kidwords.csv', names = [\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory - used for several chunks below\n",
    "directory = 'outputs/brute_force_2_with_frequency/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulate dichotomous accuracy per model and place in a file\n",
    "Extract the accuracy data for each sample and write to file. This takes a minute because it requires iterating through all the written accuracy files. Note that the accuracy summary datafile writes the accuracies out in a random order over rows, so you might need to arrange the rows if you want them to be in an orderly fashion.\n",
    "\n",
    "This routine was copied from elsewhere and needs to be inspected. The code doesn't look right to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Specify the indices\n",
    "\n",
    "# Iterate over every file in the specified directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"accuracies.csv\"):\n",
    "        # Extract the ID and level from the filename\n",
    "        id_start = filename.find(\"sample_\") + len(\"sample_\")\n",
    "        id_end = filename.find(\"hidden\")\n",
    "        ID = int(filename[id_start:id_end].replace(\"_\", \"\"))\n",
    "\n",
    "        level_start = filename.find(\"hidden_\") + len(\"hidden_\")\n",
    "        level_end = filename.find(\"accuracies\")\n",
    "        level = int(filename[level_start:level_end].replace(\"_\", \"\"))\n",
    "\n",
    "        # Read the csv file\n",
    "        data = np.genfromtxt(os.path.join(directory, filename), delimiter=',')\n",
    "\n",
    "        # Tabulate the number of values equal to one and less than one\n",
    "        equal_to_one = np.sum(data == 1)\n",
    "        less_than_one = np.sum(data < 1)\n",
    "\n",
    "        # Tabulate the values for each set of indices\n",
    "        # if you want to determine\n",
    "        train = np.sum(data[samples[:,ID]] == 1)/sum(samples[:,ID])\n",
    "        test = np.sum(data[tests[:,ID]] == 1)/sum(tests[:,ID])\n",
    "        holdout = np.sum(data[holdouts[:,ID]] == 1)/sum(holdouts[:,ID])\n",
    "\n",
    "        # Save the results\n",
    "        results.append([ID, level, train, test, holdout])\n",
    "\n",
    "# Convert the results to a numpy array and write to a csv file\n",
    "results_array = np.array(results)\n",
    "\n",
    "\n",
    "pd.DataFrame(results_array).to_csv('outputs/brute_force_2_with_frequency/tabulated_dichotomous_accuracy.csv', index = False, header = [\"model_id\", \"hidden\", \"train\", \"test\", \"holdout\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset for MSE\n",
    "This will generate a file with all the right data, but is quite large (doesn't subset by sampling). It allow you to identify data for certain values of hidden unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"sample_\"):\n",
    "        if \"error\" in filename:\n",
    "            if \"hidden_20\" in filename or \"hidden_30\" in filename or \"hidden_40\" in filename:\n",
    "                filenames.append(filename)  \n",
    "\n",
    "dfs = []\n",
    "\n",
    "for filename in filenames:\n",
    "\n",
    "    id_start = filename.find(\"sample_\") + len(\"sample_\")\n",
    "    id_end = filename.find(\"hidden\")\n",
    "    ID = int(filename[id_start:id_end].replace(\"_\", \"\"))\n",
    "\n",
    "    level_start = filename.find(\"hidden_\") + len(\"hidden_\")\n",
    "    level_end = filename.find(\"error\")\n",
    "    level = int(filename[level_start:level_end].replace(\"_\", \"\"))\n",
    "\n",
    "    one_file = pd.read_csv(f'outputs/brute_force_2_with_frequency/{filename}', names = [\"mse\"])\n",
    "    one_file['word'] = words['word']\n",
    "    one_file['model_id'] = ID\n",
    "    one_file['hidden'] = level\n",
    "    one_file['train'] = samples[:,ID]\n",
    "    one_file['test'] = tests[:,ID]\n",
    "    one_file['holdout'] = holdouts[:,ID]\n",
    "    dfs.append(one_file)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# this function needs to change if you are calculating accuracy from featurewise accuracy rather than from mse:\n",
    "df['accuracy'] = df['mse'].apply(lambda x: 0 if x > 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86070000, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/p39/lib/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mholdout\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# if you have generated a subset:\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/p39/lib/python3.9/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/p39/lib/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test'"
     ]
    }
   ],
   "source": [
    "df = df[df['test'] == False]\n",
    "df = df[['model_id', 'hidden', 'word', 'mse', 'train', 'holdout']]\n",
    "\n",
    "# if you have generated a subset:\n",
    "df.to_csv('outputs/brute_force_2_with_frequency/data_for_lmem_full.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMEM subset data\n",
    "Generate a random sample of 200 model IDs to make the subset data for the LMEM (which DK is running)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the MSE (files labeled with \"error\") data for the LMEM subset (the LMEMs can't be run on the entire dataset). This routine does look correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chunk helps subset to create data for an LMEM, if you need to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(345)\n",
    "\n",
    "N = 1000\n",
    "\n",
    "numbers = [str(i) for i in range(10000)]\n",
    "subset = random.sample(numbers, N)\n",
    "\n",
    "filenames = []\n",
    "for filename in os.listdir(directory):\n",
    "    for ID in subset:\n",
    "        if filename.startswith(\"sample_\"+ID+\"_\"):\n",
    "            if \"error\" in filename:\n",
    "              if filename or \"hidden_20\" in filename or \"hidden_30\" in filename or \"hidden_40\" in filename:\n",
    "                  filenames.append(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for filename in filenames:\n",
    "\n",
    "    id_start = filename.find(\"sample_\") + len(\"sample_\")\n",
    "    id_end = filename.find(\"hidden\")\n",
    "    ID = int(filename[id_start:id_end].replace(\"_\", \"\"))\n",
    "\n",
    "    level_start = filename.find(\"hidden_\") + len(\"hidden_\")\n",
    "    level_end = filename.find(\"error\")\n",
    "    level = int(filename[level_start:level_end].replace(\"_\", \"\"))\n",
    "\n",
    "    one_file = pd.read_csv(f'outputs/brute_force_2_with_frequency/{filename}', names = [\"mse\"])\n",
    "    one_file['word'] = words['word']\n",
    "    one_file['model_id'] = ID\n",
    "    one_file['hidden'] = level\n",
    "    one_file['train'] = samples[:,ID]\n",
    "    one_file['test'] = tests[:,ID]\n",
    "    one_file['holdout'] = holdouts[:,ID]\n",
    "    dfs.append(one_file)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# this function needs to change if you are calculating accuracy from featurewise accuracy rather than from mse:\n",
    "df['accuracy'] = df['mse'].apply(lambda x: 0 if x > 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file for LMEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mse', 'word', 'model_id', 'hidden', 'train', 'test', 'holdout',\n",
       "       'accuracy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If identifying a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['test'] == False]\n",
    "df = df[['model_id', 'hidden', 'word', 'mse', 'train', 'holdout']]\n",
    "\n",
    "# if you have generated a subset:\n",
    "df.to_csv('outputs/brute_force_2_with_frequency/subset_data_for_lmem_v2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data grouped by model or grouped by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout = df[df['holdout']==True]\n",
    "\n",
    "data_by_model_for_lmem = df_holdout.groupby(['model_id', 'hidden']).agg(\n",
    "    mse_mean=('mse', 'mean'),\n",
    "    mse_sd=('mse', 'std'),\n",
    "    count=('mse', 'size')\n",
    ").reset_index()\n",
    "\n",
    "df_train = df[df['train']==True]\n",
    "\n",
    "data_by_word_for_lmem = df_train.groupby(['word', 'hidden']).agg(\n",
    "    mse_mean=('mse', 'mean'),\n",
    "    mse_sd=('mse', 'std'),\n",
    "    count=('mse', 'size')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_model_for_lmem.to_csv('~/Desktop/data_by_model_for_lmem.csv', index=False)\n",
    "data_by_word_for_lmem.to_csv('~/Desktop/data_by_word_for_lmem.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulate summary data per model\n",
    "Using the \"...summary.csv\" files, tabulate the summary data for every model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "cols_in = ['hidden_units', 'accuracy_train', 'mse_train', 'accuracy_test', 'mse_test', 'accuracy_holdout', 'mse_holdout']\n",
    "cols_out = ['model_id', 'hidden_units', 'accuracy_train', 'mse_train', 'accuracy_test', 'mse_test', 'accuracy_holdout', 'mse_holdout']\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"summary.csv\"):\n",
    "        # Extract the ID and level from the filename\n",
    "        id_start = filename.find(\"sample_\") + len(\"sample_\")\n",
    "        id_end = filename.find(\"hidden\")\n",
    "        ID = int(filename[id_start:id_end].replace(\"_\", \"\"))\n",
    "\n",
    "        # Read the csv file\n",
    "        summary = pd.read_csv(os.path.join(directory, filename))[cols_in]\n",
    "        summary['model_id'] = ID\n",
    "\n",
    "        # Save the contents\n",
    "        results.append(summary)\n",
    "        \n",
    "\n",
    "pd.concat(results).reindex(columns=cols_out).to_csv('outputs/brute_force_2_with_frequency/model_summaries.csv', index = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
