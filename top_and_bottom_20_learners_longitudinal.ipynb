{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from keras import backend as K\n",
    "from src.learner import *\n",
    "\n",
    "def scale(x, K):\n",
    "    return K*math.log(x)\n",
    "\n",
    "samples = np.genfromtxt('data/samples.csv', delimiter=\",\").astype(bool)\n",
    "holdouts = np.genfromtxt('data/holdouts.csv', delimiter=\",\").astype(bool)\n",
    "tests = np.genfromtxt('data/tests.csv', delimiter=\",\").astype(bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "Here we take the best and worst 20 models from the 10 and 100 hidden unit conditions and run them longitudinally, saving train/test data for every point during training. We get those learners from a saved object below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_learners = pd.read_csv('data/top_and_bottom_20_learners_10_and_100_hidden_units.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>hidden_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2287</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5070</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5434</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2675</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id  hidden_units\n",
       "0      2287            10\n",
       "1      5070            10\n",
       "2      5434            10\n",
       "3      2675            10\n",
       "4      1305            10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_learners.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_10 = []\n",
    "\n",
    "hidden_100 = []\n",
    "\n",
    "for i, row in target_learners.iterrows():\n",
    "    if row.hidden_units == 10:\n",
    "        hidden_10.append(row.model_id)\n",
    "    if row.hidden_units == 100:\n",
    "        hidden_100.append(row.model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters, used in all brute force implementations:\n",
    "\n",
    "Hidden units: 100  \n",
    "Learning rate: 0.01  \n",
    "Batch size: 16  \n",
    "Epochs: 50  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs, outputs, cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/params.json', 'r') as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "X = np.genfromtxt('data/kidwords/orth-kid.csv', delimiter=\",\")\n",
    "Y = np.genfromtxt('data/kidwords/phon-kid.csv', delimiter=\",\")\n",
    "\n",
    "words = pd.read_csv('data/kidwords/kidwords.csv', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain frequencies for the frequency-weighting operation, just like the brute force implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "elp = pd.read_csv('~/research/words/elp/elp_full_5.27.16.csv')\n",
    "\n",
    "frequencies = {}\n",
    "\n",
    "for word in words:\n",
    "    rowmatch = elp[elp['Word']==word]\n",
    "    if not rowmatch.empty:\n",
    "        frequencies[word] = rowmatch['Freq_HAL'].values[0]+1\n",
    "    else:\n",
    "        frequencies[word] = 1\n",
    "\n",
    "frequencies_ = [frequencies[word] for word in words]\n",
    "weights = np.array([scale(frequency, cfg[\"K\"]) for frequency in frequencies_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and bottom learners: 10 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m             np\u001b[38;5;241m.\u001b[39msavetxt(PATH \u001b[38;5;241m+\u001b[39m efn, mse, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%0.5f\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mround\u001b[39m(end\u001b[38;5;241m-\u001b[39m\u001b[43mstart\u001b[49m, \u001b[38;5;241m4\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseconds elapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "PATH = 'outputs/top_and_bottom_20_learners/'\n",
    "hidden = 10\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample in hidden_10:\n",
    "        \n",
    "        model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "\n",
    "        for epoch in range(cfg['epochs']):\n",
    "\n",
    "            pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_' + str(epoch) + '_' + '_preds.csv'\n",
    "            afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_' + str(epoch) + '_' + '_accuracies.csv'\n",
    "            efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_' + str(epoch) + '_' + '_error.csv'\n",
    "\n",
    "            \n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs = 1, batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and bottom learners: 100 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 ...done\n",
      "233 ...done\n",
      "388 ...done\n",
      "1073 ...done\n",
      "1134 ...done\n",
      "1221 ...done\n",
      "1387 ...done\n",
      "1472 ...done\n",
      "2008 ...done\n",
      "2089 ...done\n",
      "2159 ...done\n",
      "2224 ...done\n",
      "2619 ...done\n",
      "2700 ...done\n",
      "2907 ...done\n",
      "3009 ...done\n",
      "3061 ...done\n",
      "3378 ...done\n",
      "3450 ...done\n",
      "4549 ...done\n",
      "4605 ...done\n",
      "4782 ...done\n",
      "4908 ...done\n",
      "5139 ...done\n",
      "5441 ...done\n",
      "5686 ...done\n",
      "6645 ...done\n",
      "6650 ...done\n",
      "6844 ...done\n",
      "7032 ...done\n",
      "7205 ...done\n",
      "8095 ...done\n",
      "8191 ...done\n",
      "8316 ...done\n",
      "8658 ...done\n",
      "8777 ...done\n",
      "9128 ...done\n",
      "9175 ...done\n",
      "9293 ...done\n",
      "9463 ...done\n",
      "1583.2011 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "PATH = 'outputs/top_and_bottom_20_learners/'\n",
    "hidden = 100\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample in hidden_100:\n",
    "        \n",
    "        model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "\n",
    "        for epoch in range(cfg['epochs']):\n",
    "\n",
    "            pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_' + str(epoch) + '_' + '_preds.csv'\n",
    "            afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_' + str(epoch) + '_' + '_accuracies.csv'\n",
    "            efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_' + str(epoch) + '_' + '_error.csv'\n",
    "\n",
    "            \n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs = 1, batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "        print(sample, \"...done\")\n",
    "    \n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
