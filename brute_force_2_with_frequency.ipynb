{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from src.learner import *\n",
    "\n",
    "samples = np.genfromtxt('data/samples.csv', delimiter=\",\").astype(bool)\n",
    "holdouts = np.genfromtxt('data/holdouts.csv', delimiter=\",\").astype(bool)\n",
    "tests = np.genfromtxt('data/tests.csv', delimiter=\",\").astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, K):\n",
    "    return K*math.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final hyperparameters we settled on were:\n",
    "\n",
    "Hidden units: 100  \n",
    "Learning rate: 0.01  \n",
    "Batch size: 16  \n",
    "Epochs: 50  \n",
    "\n",
    "These produced a training and testing accuracy of 0.997 and 0.986, respectively, and were associated with a runtime of under one second. While slightly higher train and test accuracies could have been achieved with more advanced tuning and training (e.g. training on more epochs) this configuration allowed us to achieve near-perfect performance on the training and holdout sets and be able to train within reasonable time horizons.  \n",
    "\n",
    "100 hidden units is the starting point. The other brute force runs (same words each iteration), we will decrease the number of hidden units by 20 succesively: 100, 80, 60, 40, 20.\n",
    "\n",
    "This procedure here differs from `brute_force_1` because we write out the test data for every word at the end of training. Not just the aggregate test data for the train and test sets respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/params.json', 'r') as f:\n",
    "    cfg = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('data/kidwords/orth-kid.csv', delimiter=\",\")\n",
    "Y = np.genfromtxt('data/kidwords/phon-kid.csv', delimiter=\",\")\n",
    "\n",
    "words = pd.read_csv('data/kidwords/kidwords.csv', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain frequencies for the frequency-weighting operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "elp = pd.read_csv('~/research/words/elp/elp_full_5.27.16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "\n",
    "for word in words:\n",
    "    rowmatch = elp[elp['Word']==word]\n",
    "    if not rowmatch.empty:\n",
    "        frequencies[word] = rowmatch['Freq_HAL'].values[0]+1\n",
    "    else:\n",
    "        frequencies[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_ = [frequencies[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAStklEQVR4nO3df4xe2X3X8fendnbzqyXe7tgytotdZNJ6K3abDmZpoErrgp0sqhepKznQ1oosGcRSUoREvf2DCCFLroRQi8BUVhpqRIll0oQ1XQi1XEJAbdadTTbJejdmp/HWHmzWky1taCK5svPlj+cGHtsznuuZ55kfJ++XNLr3nnvu3O/RWJ85vnPvc1NVSJLa8m0rXYAkafQMd0lqkOEuSQ0y3CWpQYa7JDVo/UoXAPDwww/X9u3bV7oMSVpTXnjhha9U1cRc+1ZFuG/fvp2pqamVLkOS1pQkvzffPi/LSFKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg1bFE6rSarb9yHMrct7Xjj2xIudVG5y5S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhrUK9yT/L0kF5K8lOSjSd6c5KEkZ5O82i03DPV/Jsl0kotJ9o6vfEnSXBYM9yRbgL8LTFbV9wHrgAPAEeBcVe0EznXbJNnV7X8E2AccT7JuPOVLkubS97LMeuAtSdYDbwWuAvuBk93+k8CT3fp+4FRV3aiqS8A0sHtkFUuSFrRguFfV/wT+CXAZuAb8YVX9BrCpqq51fa4BG7tDtgBXhr7FTNd2mySHk0wlmZqdnV3aKCRJt+lzWWYDg9n4DuBPAm9L8hP3OmSOtrqroepEVU1W1eTExETfeiVJPfT5VMgfBS5V1SxAko8DPwi8nmRzVV1Lshm43vWfAbYNHb+VwWUcadFW6pMZpbWqzzX3y8DjSd6aJMAe4BXgDHCw63MQeLZbPwMcSPJgkh3ATuD8aMuWJN3LgjP3qno+yceAzwI3gc8BJ4C3A6eTHGLwC+Cprv+FJKeBl7v+T1fVrTHVL0maQ6+XdVTVh4AP3dF8g8Esfq7+R4GjSytNkrRYPqEqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg/q8Q/WdSV4c+vpqkp9J8lCSs0le7ZYbho55Jsl0kotJ9o53CJKkOy0Y7lV1saoeq6rHgB8Avg58AjgCnKuqncC5bpsku4ADwCPAPuB4knXjKV+SNJf7vSyzB/jdqvo9YD9wsms/CTzZre8HTlXVjaq6BEwDu0dQqySpp/sN9wPAR7v1TVV1DaBbbuzatwBXho6Z6dpuk+RwkqkkU7Ozs/dZhiTpXnqHe5IHgB8D/t1CXedoq7saqk5U1WRVTU5MTPQtQ5LUw/3M3N8LfLaqXu+2X0+yGaBbXu/aZ4BtQ8dtBa4utVBJUn/3E+7v5/9fkgE4Axzs1g8Czw61H0jyYJIdwE7g/FILlST1t75PpyRvBf4y8DeHmo8Bp5McAi4DTwFU1YUkp4GXgZvA01V1a6RVS5LuqVe4V9XXge+8o+0NBnfPzNX/KHB0ydVJkhbFJ1QlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqUK9wT/KOJB9L8qUkryT5C0keSnI2yavdcsNQ/2eSTCe5mGTv+MqXJM2l78z9F4FPVtX3AI8CrwBHgHNVtRM4122TZBdwAHgE2AccT7Ju1IVLkua3YLgn+Q7gh4BfBqiqP66qPwD2Aye7bieBJ7v1/cCpqrpRVZeAaWD3aMuWJN1Ln5n7dwOzwL9K8rkkH07yNmBTVV0D6JYbu/5bgCtDx890bbdJcjjJVJKp2dnZJQ1CknS7PuG+HngX8C+r6vuBr9FdgplH5miruxqqTlTVZFVNTkxM9CpWktRPn3CfAWaq6vlu+2MMwv71JJsBuuX1of7bho7fClwdTbmSpD4WDPeq+l/AlSTv7Jr2AC8DZ4CDXdtB4Nlu/QxwIMmDSXYAO4HzI61aknRP63v2+2ngV5M8AHwZ+ACDXwynkxwCLgNPAVTVhSSnGfwCuAk8XVW3Rl65JGlevcK9ql4EJufYtWee/keBo4svS5K0FD6hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqUK9wT/Jaki8meTHJVNf2UJKzSV7tlhuG+j+TZDrJxSR7x1W8JGlu9zNz/+GqeqyqvvlGpiPAuaraCZzrtkmyCzgAPALsA44nWTfCmiVJC1jKZZn9wMlu/STw5FD7qaq6UVWXgGlg9xLOI0m6T33DvYDfSPJCksNd26aqugbQLTd27VuAK0PHznRtt0lyOMlUkqnZ2dnFVS9JmlOvF2QD766qq0k2AmeTfOkefTNHW93VUHUCOAEwOTl5135J0uL1mrlX1dVueR34BIPLLK8n2QzQLa933WeAbUOHbwWujqpgSdLCFgz3JG9L8u3fXAf+CvAScAY42HU7CDzbrZ8BDiR5MMkOYCdwftSFS5Lm1+eyzCbgE0m+2f/fVtUnk/wOcDrJIeAy8BRAVV1Ichp4GbgJPF1Vt8ZSvSRpTguGe1V9GXh0jvY3gD3zHHMUOLrk6iRJi+ITqpLUIMNdkhpkuEtSg/re5y5pmW0/8tyKnfu1Y0+s2Lk1Gs7cJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBvUO9yTrknwuya932w8lOZvk1W65YajvM0mmk1xMsncchUuS5nc/M/cPAq8MbR8BzlXVTuBct02SXcAB4BFgH3A8ybrRlCtJ6qNXuCfZCjwBfHioeT9wsls/CTw51H6qqm5U1SVgmsELtSVJy6TvzP0XgH8AfGOobVNVXQPolhu79i3AlaF+M13bbZIcTjKVZGp2dvZ+65Yk3cOC4Z7krwLXq+qFnt8zc7TVXQ1VJ6pqsqomJyYmen5rSVIffV7W8W7gx5K8D3gz8B1J/g3wepLNVXUtyWbgetd/Btg2dPxW4Oooi5Yk3duCM/eqeqaqtlbVdgZ/KP3NqvoJ4AxwsOt2EHi2Wz8DHEjyYJIdwE7g/MgrlyTNaymv2TsGnE5yCLgMPAVQVReSnAZeBm4CT1fVrSVXKknq7b7Cvao+BXyqW38D2DNPv6PA0SXWJklaJJ9QlaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQUt5iEnfgrYfeW6lS5DUgzN3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIa1Ocdqm9Ocj7J55NcSPKPuvaHkpxN8mq33DB0zDNJppNcTLJ3nAOQJN2tz8z9BvAjVfUo8BiwL8njwBHgXFXtBM512yTZxeB1fI8A+4DjSdaNoXZJ0jz6vEO1quqPus03dV8F7AdOdu0ngSe79f3Aqaq6UVWXgGlg9yiLliTdW69r7knWJXkRuA6crarngU1VdQ2gW27sum8BrgwdPtO1SZKWSa9wr6pbVfUYsBXYneT77tE9c32Luzolh5NMJZmanZ3tVawkqZ/7ulumqv6AwQuy9wGvJ9kM0C2vd91mgG1Dh20Frs7xvU5U1WRVTU5MTNx/5ZKkefW5W2YiyTu69bcAPwp8CTgDHOy6HQSe7dbPAAeSPJhkB7ATOD/iuiVJ99DnI383Aye7O16+DThdVb+e5LeB00kOAZeBpwCq6kKS08DLwE3g6aq6NZ7yJUlzWTDcq+oLwPfP0f4GsGeeY44CR5dcnSRpUXxCVZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoD6v2duW5L8keSXJhSQf7NofSnI2yavdcsPQMc8kmU5yMcnecQ5AknS3PjP3m8Dfr6rvBR4Hnk6yCzgCnKuqncC5bptu3wHgEQYv0j7evaJPkrRMFgz3qrpWVZ/t1v8P8AqwBdgPnOy6nQSe7Nb3A6eq6kZVXQKmgd0jrluSdA/3dc09yXYG71N9HthUVddg8AsA2Nh12wJcGTpspmu783sdTjKVZGp2dnYRpUuS5tM73JO8Hfg14Geq6qv36jpHW93VUHWiqiaranJiYqJvGZKkHnqFe5I3MQj2X62qj3fNryfZ3O3fDFzv2meAbUOHbwWujqZcSVIffe6WCfDLwCtV9U+Hdp0BDnbrB4Fnh9oPJHkwyQ5gJ3B+dCVLkhayvkefdwM/CXwxyYtd288Bx4DTSQ4Bl4GnAKrqQpLTwMsM7rR5uqpujbpwSdL8Fgz3qvrvzH0dHWDPPMccBY4uoS5J0hL4hKokNchwl6QGGe6S1KA+f1CV9C1m+5HnVuS8rx17YkXO2yJn7pLUoCZm7s4yJOl2ztwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBfd7E9JEk15O8NNT2UJKzSV7tlhuG9j2TZDrJxSR7x1W4JGl+fWbuvwLsu6PtCHCuqnYC57ptkuwCDgCPdMccT7JuZNVKknpZMNyr6tPA79/RvB842a2fBJ4caj9VVTeq6hIwDeweTamSpL4We819U1VdA+iWG7v2LcCVoX4zXdtdkhxOMpVkanZ2dpFlSJLmMuo/qM71rtWaq2NVnaiqyaqanJiYGHEZkvStbbHh/nqSzQDd8nrXPgNsG+q3Fbi6+PIkSYux2HA/Axzs1g8Czw61H0jyYJIdwE7g/NJKlCTdrwVf1pHko8B7gIeTzAAfAo4Bp5McAi4DTwFU1YUkp4GXgZvA01V1a0y1S5LmsWC4V9X759m1Z57+R4GjSylKkrQ0PqEqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDFrzPXZKWy/Yjz63IeV879sSKnHecnLlLUoMMd0lqkJdl1qCV+q+rpLXDmbskNchwl6QGGe6S1CDDXZIaZLhLUoPGdrdMkn3ALwLrgA9X1bFxnUuSlmIl70Ab1wNUY5m5J1kH/AvgvcAu4P1Jdo3jXJKku41r5r4bmK6qLwMkOQXsZ/Bu1WZ4v7mk1Wpc4b4FuDK0PQP8+eEOSQ4Dh7vNP0pycQnnexj4yhKOXyscZ1scZ1sWNc78/JLO+afm2zGucM8cbXXbRtUJ4MRITpZMVdXkKL7XauY42+I427Laxjmuu2VmgG1D21uBq2M6lyTpDuMK998BdibZkeQB4ABwZkznkiTdYSyXZarqZpK/A/xnBrdCfqSqLozjXJ2RXN5ZAxxnWxxnW1bVOFNVC/eSJK0pPqEqSQ0y3CWpQWsm3JPsS3IxyXSSI3PsT5J/1u3/QpJ3rUSdS9VjnH+jG98XkvxWkkdXos6lWmicQ/3+XJJbSX58OesblT7jTPKeJC8muZDkvy53jaPQ49/tn0jyH5J8vhvnB1aizqVK8pEk15O8NM/+1ZNDVbXqvxj8UfZ3ge8GHgA+D+y6o8/7gP/E4B77x4HnV7ruMY3zB4EN3fp7Wx3nUL/fBP4j8OMrXfeYfp7vYPDk9nd12xtXuu4xjfPngJ/v1ieA3wceWOnaFzHWHwLeBbw0z/5Vk0NrZeb+/z7OoKr+GPjmxxkM2w/86xr4DPCOJJuXu9AlWnCcVfVbVfW/u83PMHiGYK3p8/ME+Gng14Dry1ncCPUZ518HPl5VlwGqai2Otc84C/j2JAHeziDcby5vmUtXVZ9mUPt8Vk0OrZVwn+vjDLYsos9qd79jOMRglrDWLDjOJFuAvwb80jLWNWp9fp5/BtiQ5FNJXkjyU8tW3ej0Gec/B76XwcOMXwQ+WFXfWJ7yltWqyaG18oLsBT/OoGef1a73GJL8MINw/4tjrWg8+ozzF4Cfrapbg8nemtRnnOuBHwD2AG8BfjvJZ6rqf4y7uBHqM869wIvAjwB/Gjib5L9V1VfHXNtyWzU5tFbCvc/HGbTwkQe9xpDkzwIfBt5bVW8sU22j1Geck8CpLtgfBt6X5GZV/ftlqXA0+v67/UpVfQ34WpJPA48Caync+4zzA8CxGlyYnk5yCfge4PzylLhsVk0OrZXLMn0+zuAM8FPdX6sfB/6wqq4td6FLtOA4k3wX8HHgJ9fY7G7YguOsqh1Vtb2qtgMfA/72Ggt26Pfv9lngLyVZn+StDD499ZVlrnOp+ozzMoP/nZBkE/BO4MvLWuXyWDU5tCZm7jXPxxkk+Vvd/l9icEfF+4Bp4OsMZgprSs9x/kPgO4Hj3az2Zq2iT6Lro+c417w+46yqV5J8EvgC8A0Gby2b8za71arnz/MfA7+S5IsMLl38bFWtuY8BTvJR4D3Aw0lmgA8Bb4LVl0N+/IAkNWitXJaRJN0Hw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ16P8Cx5s8IPIA5F0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = np.array([scale(frequency, cfg[\"K\"]) for frequency in frequencies_])\n",
    "\n",
    "plt.hist(weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 100\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 80\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "    pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "    afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "    efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "    \n",
    "    with open(PATH + sfn, 'w') as f:\n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                \"hidden_units\",\n",
    "                                                \"learning_rate\",\n",
    "                                                \"batch_size\",\n",
    "                                                \"epochs\",\n",
    "                                                \"loss_train\",\n",
    "                                                \"accuracy_train\",\n",
    "                                                \"mse_train\",\n",
    "                                                \"loss_test\",\n",
    "                                                \"accuracy_test\",\n",
    "                                                \"mse_test\",\n",
    "                                                \"loss_holdout\",\n",
    "                                                \"accuracy_holdout\",\n",
    "                                                \"mse_holdout\"))\n",
    "\n",
    "        model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "        model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "        loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "        loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "        loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "        preds = (model.predict(X) > .5).astype(int)\n",
    "        np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "        accuracies = (preds == Y).astype(int)\n",
    "        np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "        mse = K.eval(K.mean(K.square(model.predict(X) - Y), axis = 1))\n",
    "        np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "        \n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    cfg['learning_rate'],\n",
    "                                                    cfg['batch_size'],\n",
    "                                                    cfg['epochs'],\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    loss_test,\n",
    "                                                    accuracy_test,\n",
    "                                                    mse_test,\n",
    "                                                    loss_holdout,\n",
    "                                                    accuracy_holdout,\n",
    "                                                    mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8594.5916 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "hidden = 70\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 8029:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "        \n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(model.predict(X) - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "            \n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 60 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 60\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample == 9664:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "        \n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(model.predict(X) - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "                    \n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "    end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 40\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "\n",
    "    sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "    pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "    afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "    efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "\n",
    "    with open(PATH + sfn, 'w') as f:\n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                \"hidden_units\",\n",
    "                                                \"learning_rate\",\n",
    "                                                \"batch_size\",\n",
    "                                                \"epochs\",\n",
    "                                                \"loss_train\",\n",
    "                                                \"accuracy_train\",\n",
    "                                                \"mse_train\",\n",
    "                                                \"loss_test\",\n",
    "                                                \"accuracy_test\",\n",
    "                                                \"mse_test\",\n",
    "                                                \"loss_holdout\",\n",
    "                                                \"accuracy_holdout\",\n",
    "                                                \"mse_holdout\"))\n",
    "\n",
    "        model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "        model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "        loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "        loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "        loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "        preds = (model.predict(X) > .5).astype(int)\n",
    "        np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "        accuracies = (preds == Y).astype(int)\n",
    "        np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "        mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "        np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "        \n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    cfg['learning_rate'],\n",
    "                                                    cfg['batch_size'],\n",
    "                                                    cfg['epochs'],\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    loss_test,\n",
    "                                                    accuracy_test,\n",
    "                                                    mse_test,\n",
    "                                                    loss_holdout,\n",
    "                                                    accuracy_holdout,\n",
    "                                                    mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hidden = 30\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 8256:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "            \n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 20\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 5810:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 15\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 7709:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 10\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 5136:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 5\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "    pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "    afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "    efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "    with open(PATH + sfn, 'w') as f:\n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                \"hidden_units\",\n",
    "                                                \"learning_rate\",\n",
    "                                                \"batch_size\",\n",
    "                                                \"epochs\",\n",
    "                                                \"loss_train\",\n",
    "                                                \"accuracy_train\",\n",
    "                                                \"mse_train\",\n",
    "                                                \"loss_test\",\n",
    "                                                \"accuracy_test\",\n",
    "                                                \"mse_test\",\n",
    "                                                \"loss_holdout\",\n",
    "                                                \"accuracy_holdout\",\n",
    "                                                \"mse_holdout\"))\n",
    "\n",
    "        model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "        model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "        loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "        loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "        loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "        preds = (model.predict(X) > .5).astype(int)\n",
    "        np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "        accuracies = (preds == Y).astype(int)\n",
    "        np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "        mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "        np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    cfg['learning_rate'],\n",
    "                                                    cfg['batch_size'],\n",
    "                                                    cfg['epochs'],\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    loss_test,\n",
    "                                                    accuracy_test,\n",
    "                                                    mse_test,\n",
    "                                                    loss_holdout,\n",
    "                                                    accuracy_holdout,\n",
    "                                                    mse_holdout))\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate MSE data for every word for every model after the fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = 'outputs/brute_force_2_with_frequency/'\n",
    "pattern = 'preds'\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if pattern in filename:\n",
    "        filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "\n",
    "for file in filenames:\n",
    "\n",
    "    outfile = file.replace('preds', 'error')\n",
    "    preds = np.genfromtxt(directory + file, delimiter=',')\n",
    "    mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "    np.savetxt(directory + outfile, mse, delimiter=',', fmt='%0.5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
