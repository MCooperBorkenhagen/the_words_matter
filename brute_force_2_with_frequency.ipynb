{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 07:23:25.386656: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from src.learner import *\n",
    "\n",
    "samples = np.genfromtxt('data/samples.csv', delimiter=\",\").astype(bool)\n",
    "holdouts = np.genfromtxt('data/holdouts.csv', delimiter=\",\").astype(bool)\n",
    "tests = np.genfromtxt('data/tests.csv', delimiter=\",\").astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, K):\n",
    "    return K*math.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final hyperparameters we settled on were:\n",
    "\n",
    "Hidden units: 100  \n",
    "Learning rate: 0.01  \n",
    "Batch size: 16  \n",
    "Epochs: 50  \n",
    "\n",
    "These produced a training and testing accuracy of 0.997 and 0.986, respectively, and were associated with a runtime of under one second. While slightly higher train and test accuracies could have been achieved with more advanced tuning and training (e.g. training on more epochs) this configuration allowed us to achieve near-perfect performance on the training and holdout sets and be able to train within reasonable time horizons.  \n",
    "\n",
    "100 hidden units is the starting point. The other brute force runs (same words each iteration), we will decrease the number of hidden units by 20 succesively: 100, 80, 60, 40, 20.\n",
    "\n",
    "This procedure here differs from `brute_force_1` because we write out the test data for every word at the end of training. Not just the aggregate test data for the train and test sets respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/params.json', 'r') as f:\n",
    "    cfg = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('data/kidwords/orth-kid.csv', delimiter=\",\")\n",
    "Y = np.genfromtxt('data/kidwords/phon-kid.csv', delimiter=\",\")\n",
    "\n",
    "words = pd.read_csv('data/kidwords/kidwords.csv', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2869, 260)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain frequencies for the frequency-weighting operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elp = pd.read_csv('~/research/words/elp/elp_full_5.27.16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "\n",
    "for word in words:\n",
    "    rowmatch = elp[elp['Word']==word]\n",
    "    if not rowmatch.empty:\n",
    "        frequencies[word] = rowmatch['Freq_HAL'].values[0]+1\n",
    "    else:\n",
    "        frequencies[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_ = [frequencies[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = np.array([scale(frequency, cfg[\"K\"]) for frequency in frequencies_])\n",
    "\n",
    "plt.hist(weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 100\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 07:25:13.806606: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 938us/step\n",
      "90/90 [==============================] - 0s 915us/step\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 948us/step\n",
      "90/90 [==============================] - 0s 944us/step\n",
      "90/90 [==============================] - 0s 894us/step\n",
      "90/90 [==============================] - 0s 942us/step\n",
      "90/90 [==============================] - 0s 929us/step\n",
      "90/90 [==============================] - 0s 960us/step\n",
      "90/90 [==============================] - 0s 923us/step\n",
      "90/90 [==============================] - 0s 919us/step\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 970us/step\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 955us/step\n",
      "90/90 [==============================] - 0s 937us/step\n",
      "90/90 [==============================] - 0s 903us/step\n",
      "90/90 [==============================] - 0s 948us/step\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 975us/step\n",
      "90/90 [==============================] - 0s 901us/step\n",
      "90/90 [==============================] - 0s 913us/step\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "90/90 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "hidden = 90\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 80\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "    pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "    afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "    efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "    \n",
    "    with open(PATH + sfn, 'w') as f:\n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                \"hidden_units\",\n",
    "                                                \"learning_rate\",\n",
    "                                                \"batch_size\",\n",
    "                                                \"epochs\",\n",
    "                                                \"loss_train\",\n",
    "                                                \"accuracy_train\",\n",
    "                                                \"mse_train\",\n",
    "                                                \"loss_test\",\n",
    "                                                \"accuracy_test\",\n",
    "                                                \"mse_test\",\n",
    "                                                \"loss_holdout\",\n",
    "                                                \"accuracy_holdout\",\n",
    "                                                \"mse_holdout\"))\n",
    "\n",
    "        model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "        model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "        loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "        loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "        loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "        preds = (model.predict(X) > .5).astype(int)\n",
    "        np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "        accuracies = (preds == Y).astype(int)\n",
    "        np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "        mse = K.eval(K.mean(K.square(model.predict(X) - Y), axis = 1))\n",
    "        np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "        \n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    cfg['learning_rate'],\n",
    "                                                    cfg['batch_size'],\n",
    "                                                    cfg['epochs'],\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    loss_test,\n",
    "                                                    accuracy_test,\n",
    "                                                    mse_test,\n",
    "                                                    loss_holdout,\n",
    "                                                    accuracy_holdout,\n",
    "                                                    mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8594.5916 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "hidden = 70\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 8029:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "        \n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(model.predict(X) - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "            \n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 60 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 60\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample == 9664:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "        \n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(model.predict(X) - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "                    \n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "    end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 50\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 40\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "\n",
    "    sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "    pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "    afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "    efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "\n",
    "    with open(PATH + sfn, 'w') as f:\n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                \"hidden_units\",\n",
    "                                                \"learning_rate\",\n",
    "                                                \"batch_size\",\n",
    "                                                \"epochs\",\n",
    "                                                \"loss_train\",\n",
    "                                                \"accuracy_train\",\n",
    "                                                \"mse_train\",\n",
    "                                                \"loss_test\",\n",
    "                                                \"accuracy_test\",\n",
    "                                                \"mse_test\",\n",
    "                                                \"loss_holdout\",\n",
    "                                                \"accuracy_holdout\",\n",
    "                                                \"mse_holdout\"))\n",
    "\n",
    "        model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "        model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "        loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "        loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "        loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "        preds = (model.predict(X) > .5).astype(int)\n",
    "        np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "        accuracies = (preds == Y).astype(int)\n",
    "        np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "        mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "        np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "        \n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    cfg['learning_rate'],\n",
    "                                                    cfg['batch_size'],\n",
    "                                                    cfg['epochs'],\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    loss_test,\n",
    "                                                    accuracy_test,\n",
    "                                                    mse_test,\n",
    "                                                    loss_holdout,\n",
    "                                                    accuracy_holdout,\n",
    "                                                    mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6768.444 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "hidden = 30\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 8256:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "            \n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 20\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 5810:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 15\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 7709:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 10\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    if sample > 5136:\n",
    "        sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "        pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "        afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "        efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "        with open(PATH + sfn, 'w') as f:\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    \"hidden_units\",\n",
    "                                                    \"learning_rate\",\n",
    "                                                    \"batch_size\",\n",
    "                                                    \"epochs\",\n",
    "                                                    \"loss_train\",\n",
    "                                                    \"accuracy_train\",\n",
    "                                                    \"mse_train\",\n",
    "                                                    \"loss_test\",\n",
    "                                                    \"accuracy_test\",\n",
    "                                                    \"mse_test\",\n",
    "                                                    \"loss_holdout\",\n",
    "                                                    \"accuracy_holdout\",\n",
    "                                                    \"mse_holdout\"))\n",
    "\n",
    "            model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "            model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "            loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "            loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "            loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "            preds = (model.predict(X) > .5).astype(int)\n",
    "            np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "            accuracies = (preds == Y).astype(int)\n",
    "            np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "            np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "            f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                        hidden,\n",
    "                                                        cfg['learning_rate'],\n",
    "                                                        cfg['batch_size'],\n",
    "                                                        cfg['epochs'],\n",
    "                                                        loss_train,\n",
    "                                                        accuracy_train,\n",
    "                                                        mse_train,\n",
    "                                                        loss_test,\n",
    "                                                        accuracy_test,\n",
    "                                                        mse_test,\n",
    "                                                        loss_holdout,\n",
    "                                                        accuracy_holdout,\n",
    "                                                        mse_holdout))\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 5\n",
    "PATH = 'outputs/brute_force_2_with_frequency/'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sample in range(samples.shape[1]):\n",
    "    sfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_summary.csv'\n",
    "    pfn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_preds.csv'\n",
    "    afn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_accuracies.csv'\n",
    "    efn = 'sample_' + str(sample) + '_hidden_' + str(hidden) + '_error.csv'\n",
    "\n",
    "    with open(PATH + sfn, 'w') as f:\n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                \"hidden_units\",\n",
    "                                                \"learning_rate\",\n",
    "                                                \"batch_size\",\n",
    "                                                \"epochs\",\n",
    "                                                \"loss_train\",\n",
    "                                                \"accuracy_train\",\n",
    "                                                \"mse_train\",\n",
    "                                                \"loss_test\",\n",
    "                                                \"accuracy_test\",\n",
    "                                                \"mse_test\",\n",
    "                                                \"loss_holdout\",\n",
    "                                                \"accuracy_holdout\",\n",
    "                                                \"mse_holdout\"))\n",
    "\n",
    "        model = learner(X, Y, cfg['seed'], hidden, optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "        model.fit(X[samples[:, sample]], Y[samples[:, sample]], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=False, sample_weight = weights[samples[:, sample]])\n",
    "\n",
    "        loss_train, accuracy_train, mse_train = model.evaluate(X[samples[:, sample]], Y[samples[:, sample]], verbose=0) \n",
    "        loss_test, accuracy_test, mse_test = model.evaluate(X[tests[:, sample]], Y[tests[:, sample]], verbose=0) \n",
    "        loss_holdout, accuracy_holdout, mse_holdout = model.evaluate(X[holdouts[:, sample]], Y[holdouts[:, sample]], verbose=0) \n",
    "\n",
    "        preds = (model.predict(X) > .5).astype(int)\n",
    "        np.savetxt(PATH + pfn, preds, fmt='%d', delimiter=',')\n",
    "\n",
    "        accuracies = (preds == Y).astype(int)\n",
    "        np.savetxt(PATH + afn, np.mean(accuracies, axis = 1), delimiter=',', fmt='%0.5f')\n",
    "\n",
    "        mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "        np.savetxt(PATH + efn, mse, delimiter=',', fmt='%0.5f')\n",
    "\n",
    "        f.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    cfg['learning_rate'],\n",
    "                                                    cfg['batch_size'],\n",
    "                                                    cfg['epochs'],\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    loss_test,\n",
    "                                                    accuracy_test,\n",
    "                                                    mse_test,\n",
    "                                                    loss_holdout,\n",
    "                                                    accuracy_holdout,\n",
    "                                                    mse_holdout))\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(round(end-start, 4), \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate MSE data for every word for every model after the fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = 'outputs/brute_force_2_with_frequency/'\n",
    "pattern = 'preds'\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if pattern in filename:\n",
    "        filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "\n",
    "for file in filenames:\n",
    "\n",
    "    outfile = file.replace('preds', 'error')\n",
    "    preds = np.genfromtxt(directory + file, delimiter=',')\n",
    "    mse = K.eval(K.mean(K.square(preds - Y), axis = 1))\n",
    "    np.savetxt(directory + outfile, mse, delimiter=',', fmt='%0.5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
